# -*- coding: utf-8 -*-
"""resnet50_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qeViBa4avom0SN0uMuZWViOPfgtZlA7e
"""

# Install libraries
!pip install seedir
!pip install emoji
!pip install plotly
!pip install livelossplot

import kagglehub
ademboukhris_cars_body_type_cropped_path = kagglehub.dataset_download('ademboukhris/cars-body-type-cropped')

print('Data source import complete.')

import os
import shutil

# Define the source and destination paths
source_path = ademboukhris_cars_body_type_cropped_path
destination_path = '/content/cars-body-type-cropped'

# Create the destination directory if it doesn't exist
if not os.path.exists(destination_path):
    os.makedirs(destination_path)

# Copy the contents of the source directory to the destination directory
for item in os.listdir(source_path):
    s = os.path.join(source_path, item)
    d = os.path.join(destination_path, item)
    if os.path.isdir(s):
        shutil.copytree(s, d)
    else:
        shutil.copy2(s, d)

print(f"Dataset copied from {source_path} to {destination_path}")

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import seedir as sd
from zipfile import ZipFile
import plotly.express as px
import shutil
import cv2
import glob
from PIL import Image, ImageDraw
import json
import itertools
from itertools import cycle
import seaborn as sns
from sklearn.preprocessing import label_binarize
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
    roc_auc_score,
    roc_curve,
    auc,
    cohen_kappa_score,
    matthews_corrcoef,
    log_loss,
    fbeta_score
)

## deep learning libraries
import tensorflow as tf
import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Model
from tensorflow.keras import regularizers
from tensorflow.keras.layers import (
    GlobalAveragePooling2D,
    Dense,
    BatchNormalization,
    Flatten,
    Input,
    Conv1D,
    Conv2D,
    MaxPooling2D,
    Dropout
)
from keras.models import Sequential
from tensorflow.keras.applications import MobileNetV2, EfficientNetV2S
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from tensorflow.keras.applications import efficientnet, EfficientNetV2L
from tensorflow.keras.applications.vgg19 import VGG19
from livelossplot.inputs.keras import PlotLossesCallback

train_car = glob.glob("/kaggle/input/cars-body-type-cropped/Cars_Body_Type/train/*/*")
test_car = glob.glob("/kaggle/input/cars-body-type-cropped/Cars_Body_Type/test/*/*")
valid_car = glob.glob("/kaggle/input/cars-body-type-cropped/Cars_Body_Type/valid/*/*")

#model_names = ["Convertible", "Coupe", "Hatchback", "Pick-Up", "SUV", "Sedan", "VAN"]
model_names = sorted(os.listdir('/kaggle/input/cars-body-type-cropped/Cars_Body_Type/train'))

## setting up some parameters for data augmentation
img_width, img_height = 224, 224
train_samples = len(train_car)
validation_samples = len(test_car)
testing_samples = len(valid_car)
## there are 196 different models
n_classes = len(model_names)
batch_size = 32

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',)

test_datagen = ImageDataGenerator(rescale=1./255)

valid_datagen = ImageDataGenerator(rescale=1./255)

train_path = "/kaggle/input/cars-body-type-cropped/Cars_Body_Type/train"
test_path = "/kaggle/input/cars-body-type-cropped/Cars_Body_Type/test"
valid_path = "/kaggle/input/cars-body-type-cropped/Cars_Body_Type/valid"

## converting data to a tf.data.Dataset object
train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=(img_width, img_height),
    classes=model_names,
    #subset='training',
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True,
    seed=42)

validation_generator = valid_datagen.flow_from_directory(
    valid_path,
    target_size=(img_width, img_height),
    classes=model_names,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True,
    seed=42)

testing_generator = test_datagen.flow_from_directory(
    test_path,
    target_size=(img_width, img_height),
    class_mode='categorical',
    classes=model_names,
    batch_size=batch_size,
    shuffle=False,
    seed=42)

true_classes = testing_generator.classes
class_indices = train_generator.class_indices
class_indices = dict((v,k) for k,v in class_indices.items())

def define_model(model_based, optimizer, fine_tune):
    base_model = model_based(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))

    """if fine_tune > 0:
        for layer in base_model.layers[:-fine_tune]:
            layer.trainable = False
    else:
        for layer in base_model.layers:
            layer.trainable = False"""

    for layer in base_model.layers:
        if isinstance(layer, BatchNormalization):
            layer.trainable = True
        else:
            layer.trainable = False

    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(250, activation = 'relu')(x)
    x = Dropout(0.5)(x)
    output_layer = Dense(7, activation='softmax')(x)

    model = Model(inputs=base_model.input, outputs=output_layer)

    # Compiles the model for training.
    model.compile(optimizer=optimizer,
                  loss='categorical_crossentropy',
                  metrics=['accuracy',
                           tf.keras.metrics.Precision(),
                           #tf.keras.metrics.Recall(),
                           tf.keras.metrics.AUC()])

    return model

def train_model(epochs_num,model_to_train):

    plot_loss = PlotLossesCallback()

    model_history = model_to_train.fit(train_generator,
                                       batch_size=batch_size,
                                       epochs=epochs_num,
                                       validation_data=validation_generator,
                                       steps_per_epoch=train_generator.samples // batch_size ,
                                       validation_steps=validation_generator.samples // batch_size,
                                       #callbacks=[plot_loss],
                                       verbose=1)
    return model_history

def evaluate_model(model_to_evaluate):
    model_results = model_to_evaluate.evaluate(testing_generator)

def view_plots(history_model, epochs_num):

    acc_2 = history_model.history['accuracy']
    val_acc_2 = history_model.history['val_accuracy']
    loss_2 = history_model.history['loss']
    val_loss_2 = history_model.history['val_loss']
    epochs_range = range(epochs_num)
    plt.figure(figsize=(10, 4))
    plt.subplot(1, 2, 1)
    plt.plot(epochs_range, acc_2, label='Training Accuracy')
    plt.plot(epochs_range, val_acc_2, label='Validation Accuracy')
    plt.legend(loc='lower right')
    plt.title('Training and Validation Accuracy')

    plt.subplot(1, 2, 2)
    plt.plot(epochs_range, loss_2, label='Training Loss')
    plt.plot(epochs_range, val_loss_2, label='Validation Loss')
    plt.legend(loc='upper right')
    plt.title('Training and Validation Loss')
    plt.show()

def view_performance(trained_model):
    model_preds = trained_model.predict(testing_generator)
    model_pred_classes = np.argmax(model_preds, axis=-1)

    class_names = model_names

    # Show evaluation metrics
    #model_preds_probs = trained_model.predict_proba(testing_generator)
    #print("ROC AUC score:", roc_auc_score(true_classes, model_preds_probs, average="weighted", multi_class="ovr"))
    print("Cohen’s Kappa score:", cohen_kappa_score(true_classes, model_pred_classes))
    print("Matthew’s correlation coefficient:", matthews_corrcoef(true_classes, model_pred_classes))
    #print("Log loss", log_loss(true_classes, model_preds_probs))
    #print("F-beta score", fbeta_score(true_classes, model_pred_classes, beta=7))


    # Create a classification report
    print("classification report:")
    print('\n', classification_report(true_classes, model_pred_classes, target_names=model_names), sep='')

    # Display a confusion matrix
    print("confusion matric:")
    cm = confusion_matrix(true_classes, model_pred_classes)
    cm_df = pd.DataFrame(cm,
                     index = model_names,
                     columns = model_names)

    plt.figure(figsize=(14.8,8))
    sns.heatmap(cm_df, annot=True)
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

    # Display ROC-AUC Curve
    true_labels = testing_generator.classes
    #model_preds = trained_model.predict(testing_generator)

    n_classes = len(np.unique(true_labels))
    true_labels_bin = label_binarize(true_labels, classes=np.arange(n_classes))

    n_classes = 7
    true_labels_bin = label_binarize(true_labels, classes=np.arange(n_classes))

    fpr = dict()
    tpr = dict()
    roc_auc = dict()

    for class_idx in range(n_classes):
        fpr[class_idx], tpr[class_idx], _ = roc_curve(true_labels_bin[:, class_idx], model_preds[:, class_idx])
        roc_auc[class_idx] = auc(fpr[class_idx], tpr[class_idx])

    plt.figure(figsize=(7, 5))
    colors = cycle(['blue', 'red', 'green', 'purple', 'orange'])
    for class_idx, color in zip(range(n_classes), colors):
        plt.plot(fpr[class_idx], tpr[class_idx], color=color, lw=2,
                 label='Class {} (AUC = {:.2f})'.format(class_names[class_idx], roc_auc[class_idx]))

    plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve for Multiclass Classification')
    plt.legend(loc="lower right")
    plt.show()

    # Show F-beta Scroe
    true_labels_bin = label_binarize(true_labels, classes=np.arange(7))

    # Step 4: Calculate the F-beta score for each class
    beta = 0.5  # Set the value of beta for F-beta score calculation
    f_beta_scores = []

    for class_idx in range(7):
        true_labels_class = true_labels_bin[:, class_idx]
        pred_labels_class = model_preds[:, class_idx] >= 0.5  # Binary prediction for the class (adjust threshold as needed)
        f_beta = fbeta_score(true_labels_class, pred_labels_class, beta=beta)
        f_beta_scores.append(f_beta)

    # Step 5: Average F-beta score across all classes
    avg_f_beta = np.mean(f_beta_scores)

    # Print the F-beta score for each class and the average F-beta score
    for class_idx, f_beta in enumerate(f_beta_scores):
        print('Class {}: F-beta score = {:.4f}'.format(class_names[class_idx], f_beta))
    print('Average F-beta score: {:.4f}'.format(avg_f_beta))

def plot_predictions(model, test_generator, class_indices):
    # Get all images and labels from the generator
    images = []
    true_labels = []
    for i in range(len(test_generator)):
        batch_images, batch_labels = test_generator[i]
        images.append(batch_images)
        true_labels.append(np.argmax(batch_labels, axis=1))

    images = np.concatenate(images)
    true_labels = np.concatenate(true_labels)

    # Get model predictions
    model_preds = model.predict(images)
    y_preds = np.argmax(model_preds, axis=-1)

    fig = plt.figure(figsize=(20, 10))
    # Select random indices
    random_indices = np.random.choice(len(images), size=20, replace=False)

    for i, idx in enumerate(random_indices):
        ax = fig.add_subplot(4, 5, i + 1, xticks=[], yticks=[])
        # Display the image
        ax.imshow(np.squeeze(images[idx]))

        pred_idx = y_preds[idx]
        true_idx = true_labels[idx]

        plt.tight_layout()
        ax.set_title("Prediction: {}\n True: ({})".format(class_indices[pred_idx], class_indices[true_idx]),
                     color=("green" if pred_idx == true_idx else "red"))

ResNet50_Compiled = define_model(model_based=tf.keras.applications.resnet50.ResNet50, optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), fine_tune=30)

ResNet50_History = train_model(epochs_num=80, model_to_train=ResNet50_Compiled)

evaluate_model(model_to_evaluate=ResNet50_Compiled)

view_plots(history_model=ResNet50_History, epochs_num=80)

view_performance(ResNet50_Compiled)

plot_predictions(ResNet50_Compiled, testing_generator, class_indices)

ResNet50_Compiled.save('resnet50_car_body_type_model.h5')

